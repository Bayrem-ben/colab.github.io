{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv4-Darknet-Roboflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bayrem-ben/colab.github.io/blob/main/YOLOv4_Darknet_Roboflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNVU7eu9CQj3"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "\n",
        "In this notebook, we implement [YOLOv4](https://arxiv.org/pdf/2004.10934.pdf) for training on your own dataset.\n",
        "\n",
        "We also recommend reading our blog post on [Training YOLOv4 on custom data](https://blog.roboflow.ai/training-yolov4-on-a-custom-dataset/) side by side.\n",
        "\n",
        "We will take the following steps to implement YOLOv4 on our custom data:\n",
        "* Configure our GPU environment on Google Colab\n",
        "* Install the Darknet YOLOv4 training environment\n",
        "* Download our custom dataset for YOLOv4 and set up directories\n",
        "* Configure a custom YOLOv4 training config file for Darknet\n",
        "* Train our custom YOLOv4 object detector\n",
        "* Reload YOLOv4 trained weights and make inference on test images\n",
        "\n",
        "When you are done you will have a custom detector that you can use. It will make inference like this:\n",
        "\n",
        "#### ![Roboflow Workmark](https://i.imgur.com/L0n564N.png)\n",
        "\n",
        "### **Reach out for support**\n",
        "\n",
        "If you run into any hurdles on your own data set or just want to share some cool results in your own domain, [reach out!](https://roboflow.ai) \n",
        "\n",
        "\n",
        "\n",
        "#### ![Roboflow Workmark](https://i.imgur.com/WHFqYSJ.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDTvGt2zt7cm"
      },
      "source": [
        "# Configuring cuDNN on Colab for YOLOv4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-bguKWgtxSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b73b2344-bd2e-44a1-c905-5a58cb8709cf"
      },
      "source": [
        "# CUDA: Let's check that Nvidia CUDA drivers are already pre-installed and which version is it.\n",
        "!/usr/local/cuda/bin/nvcc --version\n",
        "# We need to install the correct cuDNN according to this output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJYM7-_Had0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e912ef3-fd61-4c35-85f3-83b3481f673d"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep 26 13:59:15 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_qFPIBgvlkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ffa3373-8df8-425d-e46e-7dba202987b0"
      },
      "source": [
        "# This cell ensures you have the correct architecture for your respective GPU\n",
        "# If you command is not found, look through these GPUs, find the respective\n",
        "# GPU and add them to the archTypes dictionary\n",
        "\n",
        "# Tesla V100\n",
        "# ARCH= -gencode arch=compute_70,code=[sm_70,compute_70]\n",
        "\n",
        "# Tesla K80 \n",
        "# ARCH= -gencode arch=compute_37,code=sm_37\n",
        "\n",
        "# GeForce RTX 2080 Ti, RTX 2080, RTX 2070, Quadro RTX 8000, Quadro RTX 6000, Quadro RTX 5000, Tesla T4, XNOR Tensor Cores\n",
        "# ARCH= -gencode arch=compute_75,code=[sm_75,compute_75]\n",
        "\n",
        "# Jetson XAVIER\n",
        "# ARCH= -gencode arch=compute_72,code=[sm_72,compute_72]\n",
        "\n",
        "# GTX 1080, GTX 1070, GTX 1060, GTX 1050, GTX 1030, Titan Xp, Tesla P40, Tesla P4\n",
        "# ARCH= -gencode arch=compute_61,code=sm_61\n",
        "\n",
        "# GP100/Tesla P100 - DGX-1\n",
        "# ARCH= -gencode arch=compute_60,code=sm_60\n",
        "\n",
        "# For Jetson TX1, Tegra X1, DRIVE CX, DRIVE PX - uncomment:\n",
        "# ARCH= -gencode arch=compute_53,code=[sm_53,compute_53]\n",
        "\n",
        "# For Jetson Tx2 or Drive-PX2 uncomment:\n",
        "# ARCH= -gencode arch=compute_62,code=[sm_62,compute_62]\n",
        "import os\n",
        "os.environ['GPU_TYPE'] = str(os.popen('nvidia-smi --query-gpu=name --format=csv,noheader').read())\n",
        "\n",
        "def getGPUArch(argument):\n",
        "  try:\n",
        "    argument = argument.strip()\n",
        "    # All Colab GPUs\n",
        "    archTypes = {\n",
        "        \"Tesla V100-SXM2-16GB\": \"-gencode arch=compute_70,code=[sm_70,compute_70]\",\n",
        "        \"Tesla K80\": \"-gencode arch=compute_37,code=sm_37\",\n",
        "        \"Tesla T4\": \"-gencode arch=compute_75,code=[sm_75,compute_75]\",\n",
        "        \"Tesla P40\": \"-gencode arch=compute_61,code=sm_61\",\n",
        "        \"Tesla P4\": \"-gencode arch=compute_61,code=sm_61\",\n",
        "        \"Tesla P100-PCIE-16GB\": \"-gencode arch=compute_60,code=sm_60\"\n",
        "\n",
        "      }\n",
        "    return archTypes[argument]\n",
        "  except KeyError:\n",
        "    return \"GPU must be added to GPU Commands\"\n",
        "os.environ['ARCH_VALUE'] = getGPUArch(os.environ['GPU_TYPE'])\n",
        "\n",
        "print(\"GPU Type: \" + os.environ['GPU_TYPE'])\n",
        "print(\"ARCH Value: \" + os.environ['ARCH_VALUE'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Type: Tesla K80\n",
            "\n",
            "ARCH Value: -gencode arch=compute_37,code=sm_37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3nkYzWwMuBk"
      },
      "source": [
        "## STEP 1. Install cuDNN according to the current CUDA version\n",
        "Colab added cuDNN as an inherent install - so you don't have to do a thing - major win\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16pvdFMa1FEe"
      },
      "source": [
        "# Step 2: Installing Darknet for YOLOv4 on Colab\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9uY-38P93oz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33953f85-0a4f-45b2-e7ea-9cca45978c64"
      },
      "source": [
        "%cd /content/\n",
        "%rm -rf darknet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQEktcfj9y9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46557ec4-23e8-4a87-aa45-c28a1a8ec6dd"
      },
      "source": [
        "#we clone the fork of darknet maintained by roboflow\n",
        "#small changes have been made to configure darknet for training\n",
        "!git clone https://github.com/roboflow-ai/darknet.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'darknet'...\n",
            "remote: Enumerating objects: 13289, done.\u001b[K\n",
            "remote: Total 13289 (delta 0), reused 0 (delta 0), pack-reused 13289\u001b[K\n",
            "Receiving objects: 100% (13289/13289), 12.13 MiB | 17.42 MiB/s, done.\n",
            "Resolving deltas: 100% (9105/9105), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O6dTiq5ga0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eecac85f-5718-435a-b336-9872060ac0b4"
      },
      "source": [
        "%cd /content/darknet/\n",
        "%rm Makefile"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/darknet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyTAyEhOgd__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c851f88-a1c3-4023-f455-b3e58daa0b08"
      },
      "source": [
        "#colab occasionally shifts dependencies around, at the time of authorship, this Makefile works for building Darknet on Colab\n",
        "\n",
        "%%writefile Makefile\n",
        "GPU=1\n",
        "CUDNN=1\n",
        "CUDNN_HALF=0\n",
        "OPENCV=1\n",
        "AVX=0\n",
        "OPENMP=0\n",
        "LIBSO=1\n",
        "ZED_CAMERA=0\n",
        "ZED_CAMERA_v2_8=0\n",
        "\n",
        "# set GPU=1 and CUDNN=1 to speedup on GPU\n",
        "# set CUDNN_HALF=1 to further speedup 3 x times (Mixed-precision on Tensor Cores) GPU: Volta, Xavier, Turing and higher\n",
        "# set AVX=1 and OPENMP=1 to speedup on CPU (if error occurs then set AVX=0)\n",
        "# set ZED_CAMERA=1 to enable ZED SDK 3.0 and above\n",
        "# set ZED_CAMERA_v2_8=1 to enable ZED SDK 2.X\n",
        "\n",
        "USE_CPP=0\n",
        "DEBUG=0\n",
        "\n",
        "ARCH= -gencode arch=compute_35,code=sm_35 \\\n",
        "      -gencode arch=compute_50,code=[sm_50,compute_50] \\\n",
        "      -gencode arch=compute_52,code=[sm_52,compute_52] \\\n",
        "\t    -gencode arch=compute_61,code=[sm_61,compute_61] \\\n",
        "      -gencode arch=compute_37,code=sm_37\n",
        "\n",
        "ARCH= -gencode arch=compute_60,code=sm_60\n",
        "\n",
        "OS := $(shell uname)\n",
        "\n",
        "VPATH=./src/\n",
        "EXEC=darknet\n",
        "OBJDIR=./obj/\n",
        "\n",
        "ifeq ($(LIBSO), 1)\n",
        "LIBNAMESO=libdarknet.so\n",
        "APPNAMESO=uselib\n",
        "endif\n",
        "\n",
        "ifeq ($(USE_CPP), 1)\n",
        "CC=g++\n",
        "else\n",
        "CC=gcc\n",
        "endif\n",
        "\n",
        "CPP=g++ -std=c++11\n",
        "NVCC=nvcc\n",
        "OPTS=-Ofast\n",
        "LDFLAGS= -lm -pthread\n",
        "COMMON= -Iinclude/ -I3rdparty/stb/include\n",
        "CFLAGS=-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC\n",
        "\n",
        "ifeq ($(DEBUG), 1)\n",
        "#OPTS= -O0 -g\n",
        "#OPTS= -Og -g\n",
        "COMMON+= -DDEBUG\n",
        "CFLAGS+= -DDEBUG\n",
        "else\n",
        "ifeq ($(AVX), 1)\n",
        "CFLAGS+= -ffp-contract=fast -mavx -mavx2 -msse3 -msse4.1 -msse4.2 -msse4a\n",
        "endif\n",
        "endif\n",
        "\n",
        "CFLAGS+=$(OPTS)\n",
        "\n",
        "ifneq (,$(findstring MSYS_NT,$(OS)))\n",
        "LDFLAGS+=-lws2_32\n",
        "endif\n",
        "\n",
        "ifeq ($(OPENCV), 1)\n",
        "COMMON+= -DOPENCV\n",
        "CFLAGS+= -DOPENCV\n",
        "LDFLAGS+= `pkg-config --libs opencv4 2> /dev/null || pkg-config --libs opencv`\n",
        "COMMON+= `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv`\n",
        "endif\n",
        "\n",
        "ifeq ($(OPENMP), 1)\n",
        "CFLAGS+= -fopenmp\n",
        "LDFLAGS+= -lgomp\n",
        "endif\n",
        "\n",
        "ifeq ($(GPU), 1)\n",
        "COMMON+= -DGPU -I/usr/local/cuda/include/\n",
        "CFLAGS+= -DGPU\n",
        "ifeq ($(OS),Darwin) #MAC\n",
        "LDFLAGS+= -L/usr/local/cuda/lib -lcuda -lcudart -lcublas -lcurand\n",
        "else\n",
        "LDFLAGS+= -L/usr/local/cuda/lib64 -lcuda -lcudart -lcublas -lcurand\n",
        "endif\n",
        "endif\n",
        "\n",
        "ifeq ($(CUDNN), 1)\n",
        "COMMON+= -DCUDNN\n",
        "ifeq ($(OS),Darwin) #MAC\n",
        "CFLAGS+= -DCUDNN -I/usr/local/cuda/include\n",
        "LDFLAGS+= -L/usr/local/cuda/lib -lcudnn\n",
        "else\n",
        "CFLAGS+= -DCUDNN -I/usr/local/cudnn/include\n",
        "LDFLAGS+= -L/usr/local/cudnn/lib64 -lcudnn\n",
        "endif\n",
        "endif\n",
        "\n",
        "ifeq ($(CUDNN_HALF), 1)\n",
        "COMMON+= -DCUDNN_HALF\n",
        "CFLAGS+= -DCUDNN_HALF\n",
        "ARCH+= -gencode arch=compute_70,code=[sm_70,compute_70]\n",
        "endif\n",
        "\n",
        "ifeq ($(ZED_CAMERA), 1)\n",
        "CFLAGS+= -DZED_STEREO -I/usr/local/zed/include\n",
        "ifeq ($(ZED_CAMERA_v2_8), 1)\n",
        "LDFLAGS+= -L/usr/local/zed/lib -lsl_core -lsl_input -lsl_zed\n",
        "#-lstdc++ -D_GLIBCXX_USE_CXX11_ABI=0\n",
        "else\n",
        "LDFLAGS+= -L/usr/local/zed/lib -lsl_zed\n",
        "#-lstdc++ -D_GLIBCXX_USE_CXX11_ABI=0\n",
        "endif\n",
        "endif\n",
        "\n",
        "OBJ=image_opencv.o http_stream.o gemm.o utils.o dark_cuda.o convolutional_layer.o list.o image.o activations.o im2col.o col2im.o blas.o crop_layer.o dropout_layer.o maxpool_layer.o softmax_layer.o data.o matrix.o network.o connected_layer.o cost_layer.o parser.o option_list.o darknet.o detection_layer.o captcha.o route_layer.o writing.o box.o nightmare.o normalization_layer.o avgpool_layer.o coco.o dice.o yolo.o detector.o layer.o compare.o classifier.o local_layer.o swag.o shortcut_layer.o activation_layer.o rnn_layer.o gru_layer.o rnn.o rnn_vid.o crnn_layer.o demo.o tag.o cifar.o go.o batchnorm_layer.o art.o region_layer.o reorg_layer.o reorg_old_layer.o super.o voxel.o tree.o yolo_layer.o gaussian_yolo_layer.o upsample_layer.o lstm_layer.o conv_lstm_layer.o scale_channels_layer.o sam_layer.o\n",
        "ifeq ($(GPU), 1)\n",
        "LDFLAGS+= -lstdc++\n",
        "OBJ+=convolutional_kernels.o activation_kernels.o im2col_kernels.o col2im_kernels.o blas_kernels.o crop_layer_kernels.o dropout_layer_kernels.o maxpool_layer_kernels.o network_kernels.o avgpool_layer_kernels.o\n",
        "endif\n",
        "\n",
        "OBJS = $(addprefix $(OBJDIR), $(OBJ))\n",
        "DEPS = $(wildcard src/*.h) Makefile include/darknet.h\n",
        "\n",
        "all: $(OBJDIR) backup results setchmod $(EXEC) $(LIBNAMESO) $(APPNAMESO)\n",
        "\n",
        "ifeq ($(LIBSO), 1)\n",
        "CFLAGS+= -fPIC\n",
        "\n",
        "$(LIBNAMESO): $(OBJDIR) $(OBJS) include/yolo_v2_class.hpp src/yolo_v2_class.cpp\n",
        "\t$(CPP) -shared -std=c++11 -fvisibility=hidden -DLIB_EXPORTS $(COMMON) $(CFLAGS) $(OBJS) src/yolo_v2_class.cpp -o $@ $(LDFLAGS)\n",
        "\n",
        "$(APPNAMESO): $(LIBNAMESO) include/yolo_v2_class.hpp src/yolo_console_dll.cpp\n",
        "\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) -o $@ src/yolo_console_dll.cpp $(LDFLAGS) -L ./ -l:$(LIBNAMESO)\n",
        "endif\n",
        "\n",
        "$(EXEC): $(OBJS)\n",
        "\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) $^ -o $@ $(LDFLAGS)\n",
        "\n",
        "$(OBJDIR)%.o: %.c $(DEPS)\n",
        "\t$(CC) $(COMMON) $(CFLAGS) -c $< -o $@\n",
        "\n",
        "$(OBJDIR)%.o: %.cpp $(DEPS)\n",
        "\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) -c $< -o $@\n",
        "\n",
        "$(OBJDIR)%.o: %.cu $(DEPS)\n",
        "\t$(NVCC) $(ARCH) $(COMMON) --compiler-options \"$(CFLAGS)\" -c $< -o $@\n",
        "\n",
        "$(OBJDIR):\n",
        "\tmkdir -p $(OBJDIR)\n",
        "backup:\n",
        "\tmkdir -p backup\n",
        "results:\n",
        "\tmkdir -p results\n",
        "setchmod:\n",
        "\tchmod +x *.sh\n",
        "\n",
        ".PHONY: clean\n",
        "\n",
        "clean:\n",
        "\trm -rf $(OBJS) $(EXEC) $(LIBNAMESO) $(APPNAMESO)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Makefile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyMBDkaL-Aep"
      },
      "source": [
        "#install environment from the Makefile\n",
        "#note if you are on Colab Pro this works on a P100 GPU\n",
        "#if you are on Colab free, you may need to change the Makefile for the K80 GPU\n",
        "#this goes for any GPU, you need to change the Makefile to inform darknet which GPU you are running on.\n",
        "#note the Makefile above should work for you, if you need to tweak, try the below\n",
        "%cd /content/darknet/\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/g' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/g' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/g' Makefile\n",
        "!sed -i \"s/ARCH= -gencode arch=compute_60,code=sm_60/ARCH= ${ARCH_VALUE}/g\" Makefile\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGPDEjfAALrQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c859dc9-a1fb-4605-adca-8ae320ca0b23"
      },
      "source": [
        "#download the newly released yolov4 ConvNet weights\n",
        "%cd /content/darknet\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/darknet\n",
            "--2021-09-26 14:01:55--  https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/75388965/48bfe500-889d-11ea-819e-c4d182fcf0db?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210926%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210926T140155Z&X-Amz-Expires=300&X-Amz-Signature=22de6e0a3d79e2dfcbe8ade117e5f8aa72a574f20f87e9ac8341314c56e6b7b1&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=75388965&response-content-disposition=attachment%3B%20filename%3Dyolov4.conv.137&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-09-26 14:01:55--  https://github-releases.githubusercontent.com/75388965/48bfe500-889d-11ea-819e-c4d182fcf0db?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210926%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210926T140155Z&X-Amz-Expires=300&X-Amz-Signature=22de6e0a3d79e2dfcbe8ade117e5f8aa72a574f20f87e9ac8341314c56e6b7b1&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=75388965&response-content-disposition=attachment%3B%20filename%3Dyolov4.conv.137&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170038676 (162M) [application/octet-stream]\n",
            "Saving to: ‘yolov4.conv.137’\n",
            "\n",
            "yolov4.conv.137     100%[===================>] 162.16M  96.9MB/s    in 1.7s    \n",
            "\n",
            "2021-09-26 14:01:57 (96.9 MB/s) - ‘yolov4.conv.137’ saved [170038676/170038676]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWOiKj37l4wW"
      },
      "source": [
        "# Set up Custom Dataset for YOLOv4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbniFj-eSimL"
      },
      "source": [
        "We'll use Roboflow to convert our dataset from any format to the YOLO Darknet format. \n",
        "\n",
        "1. To do so, create a free [Roboflow account](https://app.roboflow.ai).\n",
        "2. Upload your images and their annotations (in any format: VOC XML, COCO JSON, TensorFlow CSV, etc).\n",
        "3. Apply preprocessing and augmentation steps you may like. We recommend at least `auto-orient` and a `resize` to 416x416. Generate your dataset.\n",
        "4. Export your dataset in the **YOLO Darknet format**.\n",
        "5. Copy your download link, and paste it below.\n",
        "\n",
        "See our [blog post](https://blog.roboflow.ai/training-yolov4-on-a-custom-dataset/) for greater detail.\n",
        "\n",
        "In this example, I used the open source [BCCD Dataset](https://public.roboflow.ai/object-detection/bccd). (You can `fork` it to your Roboflow account to follow along.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdj4tmT5Cmdl"
      },
      "source": [
        "\n",
        "#if you already have YOLO darknet format, you can skip this step\n",
        "%cd /content/darknet\n",
        "!curl -L \"https://public.roboflow.com/ds/G9eauDeJkG?key=sSWwF63Gn0\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiCILEbs1NII",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89786543-22eb-4658-f43d-18c72df15b9a"
      },
      "source": [
        "#Set up training file directories for custom dataset\n",
        "%cd /content/darknet/\n",
        "%cp train/_darknet.labels data/obj.names\n",
        "%mkdir data/obj\n",
        "#copy image and labels\n",
        "%cp train/*.jpg data/obj/\n",
        "%cp valid/*.jpg data/obj/\n",
        "\n",
        "%cp train/*.txt data/obj/\n",
        "%cp valid/*.txt data/obj/\n",
        "\n",
        "with open('data/obj.data', 'w') as out:\n",
        "  out.write('classes = 3\\n')\n",
        "  out.write('train = data/train.txt\\n')\n",
        "  out.write('valid = data/valid.txt\\n')\n",
        "  out.write('names = data/obj.names\\n')\n",
        "  out.write('backup = backup/')\n",
        "\n",
        "#write train file (just the image list)\n",
        "import os\n",
        "\n",
        "with open('data/train.txt', 'w') as out:\n",
        "  for img in [f for f in os.listdir('train') if f.endswith('jpg')]:\n",
        "    out.write('data/obj/' + img + '\\n')\n",
        "\n",
        "#write the valid file (just the image list)\n",
        "import os\n",
        "\n",
        "with open('data/valid.txt', 'w') as out:\n",
        "  for img in [f for f in os.listdir('valid') if f.endswith('jpg')]:\n",
        "    out.write('data/obj/' + img + '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/darknet\n",
            "mkdir: cannot create directory ‘data/obj’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HtRqO3QvjkP"
      },
      "source": [
        "# Write Custom Training Config for YOLOv4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_WJcqHhpeVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49351ab3-184f-4bb6-808c-e00dddf2845f"
      },
      "source": [
        "#we build config dynamically based on number of classes\n",
        "#we build iteratively from base config files. This is the same file shape as cfg/yolo-obj.cfg\n",
        "def file_len(fname):\n",
        "  with open(fname) as f:\n",
        "    for i, l in enumerate(f):\n",
        "      pass\n",
        "  return i + 1\n",
        "\n",
        "num_classes = file_len('train/_darknet.labels')\n",
        "print(\"writing config for a custom YOLOv4 detector detecting number of classes: \" + str(num_classes))\n",
        "\n",
        "#Instructions from the darknet repo\n",
        "#change line max_batches to (classes*2000 but not less than number of training images, and not less than 6000), f.e. max_batches=6000 if you train for 3 classes\n",
        "#change line steps to 80% and 90% of max_batches, f.e. steps=4800,5400\n",
        "if os.path.exists('./cfg/custom-yolov4-detector.cfg'): os.remove('./cfg/custom-yolov4-detector.cfg')\n",
        "\n",
        "\n",
        "with open('./cfg/custom-yolov4-detector.cfg', 'a') as f:\n",
        "  f.write('[net]' + '\\n')\n",
        "  f.write('batch=64' + '\\n')\n",
        "  #####smaller subdivisions help the GPU run faster. 12 is optimal, but you might need to change to 24,36,64####\n",
        "  f.write('subdivisions=24' + '\\n')\n",
        "  f.write('width=416' + '\\n')\n",
        "  f.write('height=416' + '\\n')\n",
        "  f.write('channels=3' + '\\n')\n",
        "  f.write('momentum=0.949' + '\\n')\n",
        "  f.write('decay=0.0005' + '\\n')\n",
        "  f.write('angle=0' + '\\n')\n",
        "  f.write('saturation = 1.5' + '\\n')\n",
        "  f.write('exposure = 1.5' + '\\n')\n",
        "  f.write('hue = .1' + '\\n')\n",
        "  f.write('\\n')\n",
        "  f.write('learning_rate=0.001' + '\\n')\n",
        "  f.write('burn_in=1000' + '\\n')\n",
        "  ######you can adjust up and down to change training time#####\n",
        "  ##Darknet does iterations with batches, not epochs####\n",
        "  # max_batches = num_classes*2000\n",
        "  max_batches = 2000\n",
        "  f.write('max_batches=' + str(max_batches) + '\\n')\n",
        "  f.write('policy=steps' + '\\n')\n",
        "  steps1 = .8 * max_batches\n",
        "  steps2 = .9 * max_batches\n",
        "  f.write('steps='+str(steps1)+','+str(steps2) + '\\n')\n",
        "\n",
        "#Instructions from the darknet repo\n",
        "#change line classes=80 to your number of objects in each of 3 [yolo]-layers:\n",
        "#change [filters=255] to filters=(classes + 5)x3 in the 3 [convolutional] before each [yolo] layer, keep in mind that it only has to be the last [convolutional] before each of the [yolo] layers.\n",
        "\n",
        "  with open('cfg/yolov4-custom2.cfg', 'r') as f2:\n",
        "    content = f2.readlines()\n",
        "    for line in content:\n",
        "      f.write(line)    \n",
        "    num_filters = (num_classes + 5) * 3\n",
        "    f.write('filters='+str(num_filters) + '\\n')\n",
        "    f.write('activation=linear')\n",
        "    f.write('\\n')\n",
        "    f.write('\\n')\n",
        "    f.write('[yolo]' + '\\n')\n",
        "    f.write('mask = 0,1,2' + '\\n')\n",
        "    f.write('anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401' + '\\n')\n",
        "    f.write('classes=' + str(num_classes) + '\\n')\n",
        "\n",
        "  with open('cfg/yolov4-custom3.cfg', 'r') as f3:\n",
        "    content = f3.readlines()\n",
        "    for line in content:\n",
        "      f.write(line)    \n",
        "    num_filters = (num_classes + 5) * 3\n",
        "    f.write('filters='+str(num_filters) + '\\n')\n",
        "    f.write('activation=linear')\n",
        "    f.write('\\n')\n",
        "    f.write('\\n')\n",
        "    f.write('[yolo]' + '\\n')\n",
        "    f.write('mask = 3,4,5' + '\\n')\n",
        "    f.write('anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401' + '\\n')\n",
        "    f.write('classes=' + str(num_classes) + '\\n')\n",
        "\n",
        "  with open('cfg/yolov4-custom4.cfg', 'r') as f4:\n",
        "    content = f4.readlines()\n",
        "    for line in content:\n",
        "      f.write(line)    \n",
        "    num_filters = (num_classes + 5) * 3\n",
        "    f.write('filters='+str(num_filters) + '\\n')\n",
        "    f.write('activation=linear')\n",
        "    f.write('\\n')\n",
        "    f.write('\\n')\n",
        "    f.write('[yolo]' + '\\n')\n",
        "    f.write('mask = 6,7,8' + '\\n')\n",
        "    f.write('anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401' + '\\n')\n",
        "    f.write('classes=' + str(num_classes) + '\\n')\n",
        "    \n",
        "  with open('cfg/yolov4-custom5.cfg', 'r') as f5:\n",
        "    content = f5.readlines()\n",
        "    for line in content:\n",
        "      f.write(line)\n",
        "\n",
        "print(\"file is written!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "writing config for a custom YOLOv4 detector detecting number of classes: 8\n",
            "file is written!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2LAciMh4Cut"
      },
      "source": [
        "#here is the file that was just written. \n",
        "#you may consider adjusting certain things\n",
        "\n",
        "#like the number of subdivisions 64 runs faster but Colab GPU may not be big enough\n",
        "#if Colab GPU memory is too small, you will need to adjust subdivisions to 16\n",
        "%cat cfg/custom-yolov4-detector.cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWrG9EGamSpH"
      },
      "source": [
        "# Train Custom YOLOv4 Detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6miYFbvExqMd"
      },
      "source": [
        "!./darknet detector train data/obj.data cfg/custom-yolov4-detector.cfg yolov4.conv.137 -dont_show -map\n",
        "#If you get CUDA out of memory adjust subdivisions above!\n",
        "#adjust max batches down for shorter training above"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBnwpBV5ZXxQ"
      },
      "source": [
        "# Infer Custom Objects with Saved YOLOv4 Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzoJQQw8Zdco"
      },
      "source": [
        "#define utility function\n",
        "def imShow(path):\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  #plt.rcParams['figure.figsize'] = [10, 5]\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3dJB6NZv4kh"
      },
      "source": [
        "#check if weigths have saved yet\n",
        "#backup houses the last weights for our detector\n",
        "#(file yolo-obj_last.weights will be saved to the build\\darknet\\x64\\backup\\ for each 100 iterations)\n",
        "#(file yolo-obj_xxxx.weights will be saved to the build\\darknet\\x64\\backup\\ for each 1000 iterations)\n",
        "#After training is complete - get result yolo-obj_final.weights from path build\\darknet\\x64\\bac\n",
        "!ls backup\n",
        "#if it is empty you haven't trained for long enough yet, you need to train for at least 100 iterations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-_E3O5Mf4Mf"
      },
      "source": [
        "#coco.names is hardcoded somewhere in the detector\n",
        "%cp data/obj.names data/coco.names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjKzw2TvZrOQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6edfa539-7e17-4313-9f83-8a6a7d20e325"
      },
      "source": [
        "\n",
        "#/test has images that we can test our detector on\n",
        "test_images = [f for f in os.listdir('test') if f.endswith('.jpg')]\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "img_path =  \"test/\" + random.choice(test_images);\n",
        "\n",
        "#test out our detector!\n",
        "!./darknet detect cfg/custom-yolov4-detector.cfg backup/custom-yolov4-detector_final.weights {img_path} -dont-show\n",
        "imShow('/content/darknet/predictions.jpg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " CUDA-version: 11010 (11020), cuDNN: 7.6.5, GPU count: 1  \n",
            " OpenCV version: 3.2.0\n",
            " compute_capability = 370, cudnn_half = 0 \n",
            "net.optimized_memory = 0 \n",
            "mini_batch = 1, batch = 24, time_steps = 1, train = 0 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv     32       3 x 3/ 1    416 x 416 x   3 ->  416 x 416 x  32 0.299 BF\n",
            "   1 conv     64       3 x 3/ 2    416 x 416 x  32 ->  208 x 208 x  64 1.595 BF\n",
            "   2 conv     64       1 x 1/ 1    208 x 208 x  64 ->  208 x 208 x  64 0.354 BF\n",
            "   3 route  1 \t\t                           ->  208 x 208 x  64 \n",
            "   4 conv     64       1 x 1/ 1    208 x 208 x  64 ->  208 x 208 x  64 0.354 BF\n",
            "   5 conv     32       1 x 1/ 1    208 x 208 x  64 ->  208 x 208 x  32 0.177 BF\n",
            "   6 conv     64       3 x 3/ 1    208 x 208 x  32 ->  208 x 208 x  64 1.595 BF\n",
            "   7 Shortcut Layer: 4,  wt = 0, wn = 0, outputs: 208 x 208 x  64 0.003 BF\n",
            "   8 conv     64       1 x 1/ 1    208 x 208 x  64 ->  208 x 208 x  64 0.354 BF\n",
            "   9 route  8 2 \t                           ->  208 x 208 x 128 \n",
            "  10 conv     64       1 x 1/ 1    208 x 208 x 128 ->  208 x 208 x  64 0.709 BF\n",
            "  11 conv    128       3 x 3/ 2    208 x 208 x  64 ->  104 x 104 x 128 1.595 BF\n",
            "  12 conv     64       1 x 1/ 1    104 x 104 x 128 ->  104 x 104 x  64 0.177 BF\n",
            "  13 route  11 \t\t                           ->  104 x 104 x 128 \n",
            "  14 conv     64       1 x 1/ 1    104 x 104 x 128 ->  104 x 104 x  64 0.177 BF\n",
            "  15 conv     64       1 x 1/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.089 BF\n",
            "  16 conv     64       3 x 3/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.797 BF\n",
            "  17 Shortcut Layer: 14,  wt = 0, wn = 0, outputs: 104 x 104 x  64 0.001 BF\n",
            "  18 conv     64       1 x 1/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.089 BF\n",
            "  19 conv     64       3 x 3/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.797 BF\n",
            "  20 Shortcut Layer: 17,  wt = 0, wn = 0, outputs: 104 x 104 x  64 0.001 BF\n",
            "  21 conv     64       1 x 1/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.089 BF\n",
            "  22 route  21 12 \t                           ->  104 x 104 x 128 \n",
            "  23 conv    128       1 x 1/ 1    104 x 104 x 128 ->  104 x 104 x 128 0.354 BF\n",
            "  24 conv    256       3 x 3/ 2    104 x 104 x 128 ->   52 x  52 x 256 1.595 BF\n",
            "  25 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            "  26 route  24 \t\t                           ->   52 x  52 x 256 \n",
            "  27 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            "  28 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n",
            "  29 conv    128       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.797 BF\n",
            "  30 Shortcut Layer: 27,  wt = 0, wn = 0, outputs:  52 x  52 x 128 0.000 BF\n",
            "  31 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n",
            "  32 conv    128       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.797 BF\n",
            "  33 Shortcut Layer: 30,  wt = 0, wn = 0, outputs:  52 x  52 x 128 0.000 BF\n",
            "  34 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n",
            "  35 conv    128       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.797 BF\n",
            "  36 Shortcut Layer: 33,  wt = 0, wn = 0, outputs:  52 x  52 x 128 0.000 BF\n",
            "  37 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n",
            "  38 conv    128       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.797 BF\n",
            "  39 Shortcut Layer: 36,  wt = 0, wn = 0, outputs:  52 x  52 x 128 0.000 BF\n",
            "  40 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n",
            "  41 conv    128       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.797 BF\n",
            "  42 Shortcut Layer: 39,  wt = 0, wn = 0, outputs:  52 x  52 x 128 0.000 BF\n",
            "  43 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n",
            "  44 conv    128       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.797 BF\n",
            "  45 Shortcut Layer: 42,  wt = 0, wn = 0, outputs:  52 x  52 x 128 0.000 BF\n",
            "  46 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n",
            "  47 conv    128       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.797 BF\n",
            "  48 Shortcut Layer: 45,  wt = 0, wn = 0, outputs:  52 x  52 x 128 0.000 BF\n",
            "  49 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n",
            "  50 conv    128       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.797 BF\n",
            "  51 Shortcut Layer: 48,  wt = 0, wn = 0, outputs:  52 x  52 x 128 0.000 BF\n",
            "  52 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n",
            "  53 route  52 25 \t                           ->   52 x  52 x 256 \n",
            "  54 conv    256       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 256 0.354 BF\n",
            "  55 conv    512       3 x 3/ 2     52 x  52 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  56 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  57 route  55 \t\t                           ->   26 x  26 x 512 \n",
            "  58 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  59 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n",
            "  60 conv    256       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.797 BF\n",
            "  61 Shortcut Layer: 58,  wt = 0, wn = 0, outputs:  26 x  26 x 256 0.000 BF\n",
            "  62 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n",
            "  63 conv    256       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.797 BF\n",
            "  64 Shortcut Layer: 61,  wt = 0, wn = 0, outputs:  26 x  26 x 256 0.000 BF\n",
            "  65 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n",
            "  66 conv    256       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.797 BF\n",
            "  67 Shortcut Layer: 64,  wt = 0, wn = 0, outputs:  26 x  26 x 256 0.000 BF\n",
            "  68 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n",
            "  69 conv    256       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.797 BF\n",
            "  70 Shortcut Layer: 67,  wt = 0, wn = 0, outputs:  26 x  26 x 256 0.000 BF\n",
            "  71 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n",
            "  72 conv    256       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.797 BF\n",
            "  73 Shortcut Layer: 70,  wt = 0, wn = 0, outputs:  26 x  26 x 256 0.000 BF\n",
            "  74 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n",
            "  75 conv    256       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.797 BF\n",
            "  76 Shortcut Layer: 73,  wt = 0, wn = 0, outputs:  26 x  26 x 256 0.000 BF\n",
            "  77 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n",
            "  78 conv    256       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.797 BF\n",
            "  79 Shortcut Layer: 76,  wt = 0, wn = 0, outputs:  26 x  26 x 256 0.000 BF\n",
            "  80 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n",
            "  81 conv    256       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.797 BF\n",
            "  82 Shortcut Layer: 79,  wt = 0, wn = 0, outputs:  26 x  26 x 256 0.000 BF\n",
            "  83 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n",
            "  84 route  83 56 \t                           ->   26 x  26 x 512 \n",
            "  85 conv    512       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 512 0.354 BF\n",
            "  86 conv   1024       3 x 3/ 2     26 x  26 x 512 ->   13 x  13 x1024 1.595 BF\n",
            "  87 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            "  88 route  86 \t\t                           ->   13 x  13 x1024 \n",
            "  89 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            "  90 conv    512       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.089 BF\n",
            "  91 conv    512       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.797 BF\n",
            "  92 Shortcut Layer: 89,  wt = 0, wn = 0, outputs:  13 x  13 x 512 0.000 BF\n",
            "  93 conv    512       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.089 BF\n",
            "  94 conv    512       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.797 BF\n",
            "  95 Shortcut Layer: 92,  wt = 0, wn = 0, outputs:  13 x  13 x 512 0.000 BF\n",
            "  96 conv    512       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.089 BF\n",
            "  97 conv    512       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.797 BF\n",
            "  98 Shortcut Layer: 95,  wt = 0, wn = 0, outputs:  13 x  13 x 512 0.000 BF\n",
            "  99 conv    512       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.089 BF\n",
            " 100 conv    512       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.797 BF\n",
            " 101 Shortcut Layer: 98,  wt = 0, wn = 0, outputs:  13 x  13 x 512 0.000 BF\n",
            " 102 conv    512       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.089 BF\n",
            " 103 route  102 87 \t                           ->   13 x  13 x1024 \n",
            " 104 conv   1024       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x1024 0.354 BF\n",
            " 105 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            " 106 conv   1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
            " 107 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            " 108 max                5x 5/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.002 BF\n",
            " 109 route  107 \t\t                           ->   13 x  13 x 512 \n",
            " 110 max                9x 9/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.007 BF\n",
            " 111 route  107 \t\t                           ->   13 x  13 x 512 \n",
            " 112 max               13x13/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.015 BF\n",
            " 113 route  112 110 108 107 \t                   ->   13 x  13 x2048 \n",
            " 114 conv    512       1 x 1/ 1     13 x  13 x2048 ->   13 x  13 x 512 0.354 BF\n",
            " 115 conv   1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
            " 116 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            " 117 conv    256       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x 256 0.044 BF\n",
            " 118 upsample                 2x    13 x  13 x 256 ->   26 x  26 x 256\n",
            " 119 route  85 \t\t                           ->   26 x  26 x 512 \n",
            " 120 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            " 121 route  120 118 \t                           ->   26 x  26 x 512 \n",
            " 122 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            " 123 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            " 124 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            " 125 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            " 126 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            " 127 conv    128       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 128 0.044 BF\n",
            " 128 upsample                 2x    26 x  26 x 128 ->   52 x  52 x 128\n",
            " 129 route  54 \t\t                           ->   52 x  52 x 256 \n",
            " 130 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            " 131 route  130 128 \t                           ->   52 x  52 x 256 \n",
            " 132 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            " 133 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            " 134 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            " 135 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            " 136 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            " 137 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            " 138 conv     39       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x  39 0.054 BF\n",
            " 139 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, cls_norm: 1.00, scale_x_y: 1.20\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            " 140 route  136 \t\t                           ->   52 x  52 x 128 \n",
            " 141 conv    256       3 x 3/ 2     52 x  52 x 128 ->   26 x  26 x 256 0.399 BF\n",
            " 142 route  141 126 \t                           ->   26 x  26 x 512 \n",
            " 143 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            " 144 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            " 145 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            " 146 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            " 147 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            " 148 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            " 149 conv     39       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x  39 0.027 BF\n",
            " 150 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, cls_norm: 1.00, scale_x_y: 1.10\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            " 151 route  147 \t\t                           ->   26 x  26 x 256 \n",
            " 152 conv    512       3 x 3/ 2     26 x  26 x 256 ->   13 x  13 x 512 0.399 BF\n",
            " 153 route  152 116 \t                           ->   13 x  13 x1024 \n",
            " 154 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            " 155 conv   1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
            " 156 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            " 157 conv   1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
            " 158 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            " 159 conv   1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
            " 160 conv     39       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x  39 0.013 BF\n",
            " 161 yolo\n",
            "[yolo] params: iou loss: ciou (4), iou_norm: 0.07, cls_norm: 1.00, scale_x_y: 1.05\n",
            "nms_kind: greedynms (1), beta = 0.600000 \n",
            "Total BFLOPS 59.614 \n",
            "avg_outputs = 490698 \n",
            " Allocate additional workspace_size = 12.46 MB \n",
            "Loading weights from backup/custom-yolov4-detector_final.weights...Couldn't open file: backup/custom-yolov4-detector_final.weights\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-3040e7946209>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#test out our detector!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./darknet detect cfg/custom-yolov4-detector.cfg backup/custom-yolov4-detector_final.weights {img_path} -dont-show'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mimShow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/darknet/predictions.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-503261adaacf>\u001b[0m in \u001b[0;36mimShow\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mresized_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    }
  ]
}